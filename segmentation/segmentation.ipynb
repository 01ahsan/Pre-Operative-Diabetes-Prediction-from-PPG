{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f697e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# segment_30_fixed_1sec.py\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "INPUT_DIR = ## Set input directory ##\n",
    "OUTPUT_DIR =## Set output directory ##\n",
    "ORIGINAL_FS = 100\n",
    "SEGMENT_SAMPLES_100HZ = ORIGINAL_FS\n",
    "SEGMENTS_PER_UID = 30\n",
    "INCLUDE_1HZ = True\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def longest_valid_block(arr):\n",
    "    valid = np.isfinite(arr)\n",
    "    if not np.any(valid):\n",
    "        return 0, -1\n",
    "    diff = np.diff(np.concatenate(([False], valid, [False]))).astype(int)\n",
    "    starts = np.where(diff == 1)[0]\n",
    "    ends = np.where(diff == -1)[0] - 1\n",
    "    lengths = ends - starts + 1\n",
    "    best = np.argmax(lengths)\n",
    "    return int(starts[best]), int(ends[best])\n",
    "\n",
    "def make_30_segments(signal_100hz, uid, case_id):\n",
    "    start_idx, end_idx = longest_valid_block(signal_100hz)\n",
    "    if end_idx < start_idx:\n",
    "        print(f\"UID {uid}: no valid data\")\n",
    "        return []\n",
    "    valid = signal_100hz[start_idx:end_idx + 1]\n",
    "    total_samples = len(valid)\n",
    "    min_needed = SEGMENTS_PER_UID * SEGMENT_SAMPLES_100HZ + (SEGMENTS_PER_UID - 1) * SEGMENT_SAMPLES_100HZ\n",
    "    if total_samples < min_needed:\n",
    "        print(f\"UID {uid}: only {total_samples} samples, not enough for 30 segments\")\n",
    "        return []\n",
    "    step_samples = (total_samples - SEGMENT_SAMPLES_100HZ) // (SEGMENTS_PER_UID - 1)\n",
    "    segments = []\n",
    "    for i in range(SEGMENTS_PER_UID):\n",
    "        s = i * step_samples\n",
    "        e = s + SEGMENT_SAMPLES_100HZ\n",
    "        seg_100hz = valid[s:e]\n",
    "        seg_1hz = None\n",
    "        if INCLUDE_1HZ:\n",
    "            seg_1hz = [float(np.mean(seg_100hz))]\n",
    "        start_sec = (start_idx + s) / ORIGINAL_FS\n",
    "        center_sec = start_sec + 0.5\n",
    "        segments.append({\n",
    "            \"case_id\": str(case_id),\n",
    "            \"uid\": str(uid),\n",
    "            \"segment_idx\": i,\n",
    "            \"start_sample\": int(start_idx + s),\n",
    "            \"end_sample\": int(start_idx + e - 1),\n",
    "            \"start_time_sec\": round(start_sec, 3),\n",
    "            \"center_time_sec\": round(center_sec, 3),\n",
    "            \"duration_sec\": 1.0,\n",
    "            \"data_100hz\": seg_100hz.tolist(),\n",
    "            \"data_1hz\": seg_1hz\n",
    "        })\n",
    "    print(f\"UID {uid}: 30 segments, step={step_samples} samples ({step_samples/ORIGINAL_FS:.2f}s)\")\n",
    "    return segments\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, (np.floating, np.float64)):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, (np.integer, np.int64)):\n",
    "            return int(obj)\n",
    "        return super().default(obj)\n",
    "\n",
    "def process_file(json_path):\n",
    "    fname = os.path.basename(json_path)\n",
    "    out_path = os.path.join(OUTPUT_DIR, f\"seg30_{fname}\")\n",
    "    print(f\"\\n=== {fname} ===\")\n",
    "    t0 = time.time()\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    if not isinstance(data, dict):\n",
    "        print(\"Not a dict of UID: list\")\n",
    "        return\n",
    "    result = {}\n",
    "    total_seg = 0\n",
    "    for uid_str, values in data.items():\n",
    "        uid = int(uid_str)\n",
    "        case_id = uid\n",
    "        sig = np.array(values, dtype=np.float64)\n",
    "        segs = make_30_segments(sig, uid, case_id)\n",
    "        if segs:\n",
    "            result.setdefault(str(case_id), {})[str(uid)] = segs\n",
    "            total_seg += len(segs)\n",
    "    if total_seg:\n",
    "        with open(out_path, \"w\") as f:\n",
    "            json.dump(result, f, indent=2, cls=NumpyEncoder)\n",
    "        print(f\"Saved {total_seg} segments to {out_path} ({time.time()-t0:.2f}s)\")\n",
    "    else:\n",
    "        print(\"No segments produced.\")\n",
    "\n",
    "def main():\n",
    "    json_files = [os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if f.lower().endswith('.json')]\n",
    "    print(f\"Found {len(json_files)} JSON files\")\n",
    "    for fp in json_files:\n",
    "        process_file(fp)\n",
    "    print(\"done\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
